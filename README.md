# ğŸ“¸ CaptureSmart: Intelligent Camera Settings Assistant

![Android](https://img.shields.io/badge/Platform-Android-green)
![Python](https://img.shields.io/badge/Language-Python-blue)
![TensorFlow](https://img.shields.io/badge/Framework-TensorFlow-orange)
![Flask](https://img.shields.io/badge/Backend-Flask-lightgrey)
![Hackathon](https://img.shields.io/badge/Event-CS671_Hackathon-purple)

**CaptureSmart** is an AI-powered Android application developed for the **CS-671: Deep Learning & Its Applications Hackathon** at **IIT Mandi** (Group 34). The system helps photographers minimize motion blur by automatically recommending optimal **ISO** and **Shutter Speed** settings based on real-time image analysis.

## âœ¨ Key Features
- Real-time motion blur detection using custom MobileNetV2 model
- Intelligent ISO and shutter speed recommendations
- Low-latency Flask API backend
- Camera parameter prediction using trained MLP models
- Wi-Fi optimized for rapid image processing (~0.5-1s response)
- Comprehensive blur assessment with 7 visual feature extraction
- Synthetic blur augmentation pipeline for robust training

## ğŸ§© System Architecture
Android Camera â†’ Capture Image â†’ Send to Flask API â†’ Preprocess Image â†’ Blur Detection Model (MobileNetV2) â†’ Extract Features (Laplacian, Tenengrad, etc) â†’ ISO & Shutter Speed Prediction (MLP) â†’ Return JSON to App â†’ Display Recommendations

## ğŸ› ï¸ Installation

### Backend Setup
Clone repository:
git clone https://github.com/yourusername/CaptureSmart.git  
cd CaptureSmart/API/

Create and activate virtual environment:
python -m venv venv  
source venv/bin/activate  (for Windows: venv\Scripts\activate)

Install dependencies:
pip install -r requirements.txt

Start server (runs on http://0.0.0.0:5001):
python api.py

### Android App Setup
- Open `Android_App` in Android Studio
- Update API endpoint in `app/src/main/java/com/example/capturesmart/network/NetworkService.kt`:
  private const val BASE_URL = "http://YOUR_LOCAL_IP:5001/"
- Build and run on physical Android device (API 26+)
- Grant camera and internet permissions when prompted

## ğŸ“‚ Directory Structure

CaptureSmart/  
â”œâ”€â”€ API/ (Flask server)  
â”‚   â”œâ”€â”€ api.py  
â”‚   â”œâ”€â”€ requirements.txt  
â”‚   â”œâ”€â”€ blur_detection.py  
â”‚   â””â”€â”€ settings_predictor.py  
â”œâ”€â”€ Android_App/  
â”‚   â”œâ”€â”€ app/src/main/java/com/example/capturesmart/  
â”‚   â”‚   â”œâ”€â”€ camera/  
â”‚   â”‚   â”œâ”€â”€ network/  
â”‚   â”‚   â””â”€â”€ ui/  
â”‚   â”œâ”€â”€ res/  
â”‚   â””â”€â”€ build.gradle  
â”œâ”€â”€ Models/  
â”‚   â”œâ”€â”€ Blur_Detection/blur_detection_model_v2.h5  
â”‚   â””â”€â”€ Settings_Prediction/  
â”‚       â”œâ”€â”€ iso_classifier_model.h5  
â”‚       â”œâ”€â”€ iso_class_to_label.pkl  
â”‚       â”œâ”€â”€ iso_feature_scaler.pkl  
â”‚       â”œâ”€â”€ final_mlp_model_shutter.h5  
â”‚       â”œâ”€â”€ final_scaler_shutter.pkl  
â”‚       â””â”€â”€ stable_shutter_model.h5  
â”œâ”€â”€ Training/  
â”‚   â”œâ”€â”€ Blur_Detection/  
â”‚   â”‚   â”œâ”€â”€ blur_detection_train.ipynb  
â”‚   â”‚   â”œâ”€â”€ blur_detection_test.ipynb  
â”‚   â”‚   â””â”€â”€ dataset_creation.py  
â”‚   â””â”€â”€ Settings_Prediction/  
â”‚       â”œâ”€â”€ iso_train.py  
â”‚       â”œâ”€â”€ iso_test.py  
â”‚       â”œâ”€â”€ ss_train.py  
â”‚       â”œâ”€â”€ ss_test.py  
â”‚       â””â”€â”€ feature_extractor.py  
â”œâ”€â”€ Dataset/  
â”‚   â”œâ”€â”€ sharp_images/  
â”‚   â”œâ”€â”€ motion_blur/  
â”‚   â””â”€â”€ gaussian_blur/  
â”œâ”€â”€ ProjectReportGroup34.pdf  
â”œâ”€â”€ LICENSE  
â””â”€â”€ README.md

## ğŸŒ API Endpoint

POST /recommend_settings  
Request: image (JPEG, multipart/form-data)  
Response:  
{
  "blur_score": 41.23,
  "recommended_iso": 400,
  "recommended_shutter_speed": "1/125"
}

## ğŸ”¬ Technical Details

### Blur Detection Model
- Architecture: MobileNetV2 with custom regression head  
- Input: 224Ã—224 RGB images  
- Output: Continuous blur score (0-100)  
- Training Data: 6,000 sharp images + 18,000 blurred (12k motion, 6k Gaussian)  
- Augmentations: Random crop, flip, rotate  
- Training: 50 epochs, batch size 32, Adam optimizer  
- MAE: 6.7 | Pearson Correlation: 0.89

### ISO & Shutter Speed Prediction

#### Features Used:
- Laplacian Variance  
- Tenengrad Score  
- Perceptual Blur Metric  
- Edge Density  
- Mean Brightness  
- Histogram Mean  
- Histogram Variance

#### Model:
- MLP: Dense(64) â†’ ReLU â†’ BatchNorm â†’ Dropout â†’ Dense(32) â†’ ReLU â†’ Output  
- ISO: Range 50â€“2500, MAE: 92.8  
- Shutter Speed: Log(1/t) transformation, MAE: 0.37 EV

## ğŸ“Š Performance Comparison

| Method               | MSE   | MAE  | Pearson |
|----------------------|-------|------|---------|
| Our MobileNetV2      | 92.3  | 6.7  | 0.89    |
| Laplacian Variance   | 142.6 | 9.8  | 0.71    |
| Tenengrad Score      | 138.2 | 9.5  | 0.73    |
| Perceptual Blur      | 125.9 | 8.2  | 0.79    |

## ğŸ“¸ Sample Recommendations

| Scenario              | Blur Score | Recommended ISO | Recommended SS |
|-----------------------|------------|------------------|----------------|
| Bright daylight       | 12.3       | 100              | 1/640          |
| Indoor portrait       | 29.4       | 200              | 1/250          |
| Fast-moving subject   | 61.7       | 1250             | 1/30           |
| Low-light scene       | 84.2       | 2500             | 1/15           |

## ğŸš€ Future Roadmap (To not be continued for now)

### Feature Expansion
- Aperture recommendation  
- White balance auto-adjustment  
- Long exposure + night mode  
- Subject tracking  

### Performance Boost
- Quantization-aware training  
- Model pruning  
- Knowledge distillation  
- Hardware acceleration  

## ğŸ‘¥ Contributors (Group 34 - IIT Mandi)

| Name                       | 
|----------------------------|
| Aditya Tayal               | 
| Mayur Arora                |
| Kinshuk Chauhan            |
| Mankirat Singh Saini       |
| Yatin Gupta                |
| Karanpreet Singh Dhaliwal  |



## ğŸ”— Acknowledgements

- Course: CS-671: Deep Learning & Its Applications  
- Institution: Indian Institute of Technology, Mandi  
- Mentors: Dr. Aditya Nigam, Dr. Arnav Bhavsar  
- Dataset Sources: Manual Images clicked by our cameras
